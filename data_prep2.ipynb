{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "   \n",
    "# Read CSV file\n",
    "data = pd.read_csv('sncb_data_challenge.csv', sep=';')\n",
    "\n",
    "#Convert string to list of integers\n",
    "col_list = ['vehicles_sequence', 'events_sequence','seconds_to_incident_sequence']\n",
    "for col in col_list:\n",
    "    print(col)\n",
    "    data[col] = data[col].apply(lambda x: list(map(int, x.strip('[]').split(','))))\n",
    "\n",
    "#Convert string to list of floats\n",
    "data['train_kph_sequence'] = data['train_kph_sequence'].apply(lambda x: list(map(float, x.strip('[]').split(','))))\n",
    "\n",
    "# Print the type for each column\n",
    "for col in data.columns:\n",
    "    print(f\"{col}: {type(data[col][0])}\")\n",
    "\n",
    "# Compute the acceleration\n",
    "data['acceleration_seq'] = data.apply(\n",
    "    lambda row: [\n",
    "        (row['train_kph_sequence'][i + 1] - row['train_kph_sequence'][i]) / \n",
    "        (row['seconds_to_incident_sequence'][i + 1] - row['seconds_to_incident_sequence'][i])\n",
    "        if (row['seconds_to_incident_sequence'][i + 1] - row['seconds_to_incident_sequence'][i]) != 0 and row['vehicles_sequence'][i+1] == row['vehicles_sequence'][i] else np.nan\n",
    "        for i in range(len(row['train_kph_sequence']) - 1)\n",
    "    ], axis=1)\n",
    "\n",
    "for i in range(len(data['events_sequence'])):\n",
    "    new_vehicles_sequence = []\n",
    "    new_events_sequence = []\n",
    "    new_train_kph_sequence = []\n",
    "    new_seconds_to_incident_sequence = []\n",
    "    new_acceleration_seq = []\n",
    "    \n",
    "    for j in range(len(data['events_sequence'][i])):\n",
    "        if j == 0 or data['events_sequence'][i][j] != data['events_sequence'][i][j-1]:\n",
    "            new_vehicles_sequence.append(data['vehicles_sequence'][i][j])\n",
    "            new_events_sequence.append(data['events_sequence'][i][j])\n",
    "            new_train_kph_sequence.append(data['train_kph_sequence'][i][j])\n",
    "            new_seconds_to_incident_sequence.append(data['seconds_to_incident_sequence'][i][j])\n",
    "            if j < len(data['acceleration_seq'][i]):\n",
    "                new_acceleration_seq.append(data['acceleration_seq'][i][j])\n",
    "    \n",
    "    data.at[i, 'vehicles_sequence'] = new_vehicles_sequence\n",
    "    data.at[i, 'events_sequence'] = new_events_sequence\n",
    "    data.at[i, 'train_kph_sequence'] = new_train_kph_sequence\n",
    "    data.at[i, 'seconds_to_incident_sequence'] = new_seconds_to_incident_sequence\n",
    "    data.at[i, 'acceleration_seq'] = new_acceleration_seq\n",
    "\n",
    "for i in range(len(data['events_sequence'])):\n",
    "    for j in range(len(data['events_sequence'][i]) - 1):\n",
    "        if data['events_sequence'][i][j] == data['events_sequence'][i][j+1]:\n",
    "            print(\"duplicates\")\n",
    "            print(i)\n",
    "            print(len(data['events_sequence'][i]))\n",
    "            print(j)\n",
    "            raise ValueError(\"Duplicates in events_sequence\")\n",
    "    \n",
    "# Save the modified DataFrame to a new CSV file\n",
    "data.to_csv('sncb_prepared.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the most frequent sequence of events for each type of incident in the dataset using the FP-Growth algorithm\n",
    "data = pd.read_csv('sncb_prepared.csv', sep=';')\n",
    "\n",
    "def fb_growth(data, min_support=0.1):\n",
    "    # Create a dictionary to store the support of each item\n",
    "    support = {}\n",
    "    for index, row in data.iterrows():\n",
    "        for event in row['events_sequence']:\n",
    "            if event in support:\n",
    "                support[event] += 1\n",
    "            else:\n",
    "                support[event] = 1\n",
    "\n",
    "    # Filter the items that have a support greater than the minimum support\n",
    "    frequent_items = {k: v for k, v in support.items() if v / len(data) >= min_support}\n",
    "\n",
    "    # Create a dictionary to store the support of each itemset\n",
    "    support = {}\n",
    "    for index, row in data.iterrows():\n",
    "        for i in range(len(row['events_sequence'])):\n",
    "            for j in range(i + 1, len(row['events_sequence'])):\n",
    "                if row['events_sequence'][i] in frequent_items and row['events_sequence'][j] in frequent_items:\n",
    "                    if (row['events_sequence'][i], row['events_sequence'][j]) in support:\n",
    "                        support[(row['events_sequence'][i], row['events_sequence'][j])] += 1\n",
    "                    else:\n",
    "                        support[(row['events_sequence'][i], row['events_sequence'][j])] = 1\n",
    "\n",
    "    # Filter the itemsets that have a support greater than the minimum support\n",
    "    frequent_itemsets = {k: v for k, v in support.items() if v / len(data) >= min_support}\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "print(fb_growth(data, min_support=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4100   4102   4104   4106   2058  4110   4112   4114   4120   4122  ...  \\\n",
      "0    True  False  False  False  False  True  False  False   True  False  ...   \n",
      "1    True  False  False  False  False  True  False   True   True  False  ...   \n",
      "2   False  False  False  False  False  True  False   True   True   True  ...   \n",
      "3    True  False  False  False  False  True  False   True  False  False  ...   \n",
      "4    True  False  False  False  False  True  False  False   True  False  ...   \n",
      "..    ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  ...   \n",
      "73   True  False  False  False  False  True  False   True   True  False  ...   \n",
      "74   True  False  False  False  False  True  False   True   True  False  ...   \n",
      "75   True  False  False  False  False  True  False  False   True  False  ...   \n",
      "76   True  False  False  False  False  True  False  False   True  False  ...   \n",
      "77  False  False  False  False  False  True  False   True   True  False  ...   \n",
      "\n",
      "     4070   4072   4076   4078   4080   4082   4084   4090   4092   4094  \n",
      "0   False   True  False  False  False   True   True   True   True   True  \n",
      "1    True  False  False   True  False   True   True   True   True   True  \n",
      "2   False  False  False   True  False  False  False  False   True   True  \n",
      "3   False   True  False  False   True  False  False  False  False  False  \n",
      "4   False   True  False  False  False   True   True   True   True   True  \n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "73  False   True  False  False  False   True   True   True   True   True  \n",
      "74   True   True  False  False  False   True   True   True   True   True  \n",
      "75  False   True  False  False  False   True   True   True   True   True  \n",
      "76  False  False  False  False  False   True   True   True   True   True  \n",
      "77  False  False  False  False   True  False  False  False  False  False  \n",
      "\n",
      "[78 rows x 387 columns]\n",
      "Incident Type: 4\n",
      "     support                  itemsets\n",
      "0   1.000000                    (4026)\n",
      "8   1.000000              (4026, 2708)\n",
      "1   1.000000                    (2708)\n",
      "10  0.948718              (4026, 4148)\n",
      "9   0.948718              (2708, 4148)\n",
      "11  0.948718        (2708, 4026, 4148)\n",
      "2   0.948718                    (4148)\n",
      "5   0.935897                    (2742)\n",
      "4   0.935897                    (4066)\n",
      "3   0.935897                    (4068)\n",
      "22  0.935897              (2708, 2742)\n",
      "12  0.935897              (2708, 4068)\n",
      "13  0.935897              (4026, 4068)\n",
      "14  0.935897        (2708, 4026, 4068)\n",
      "15  0.935897              (4066, 2708)\n",
      "16  0.935897              (4026, 4066)\n",
      "18  0.935897        (4026, 2708, 4066)\n",
      "24  0.935897        (4026, 2708, 2742)\n",
      "23  0.935897              (4026, 2742)\n",
      "27  0.923077        (2708, 4026, 4394)\n",
      "26  0.923077              (4026, 4394)\n",
      "25  0.923077              (4394, 2708)\n",
      "17  0.923077              (4066, 4068)\n",
      "21  0.923077  (2708, 4026, 4068, 4066)\n",
      "20  0.923077        (4026, 4068, 4066)\n",
      "19  0.923077        (2708, 4066, 4068)\n",
      "6   0.923077                    (4394)\n",
      "7   0.910256                    (4120)\n",
      "28  0.910256              (4120, 2742)\n",
      "29  0.910256              (4120, 2708)\n",
      "30  0.910256              (4120, 4026)\n",
      "31  0.910256        (4120, 2708, 2742)\n",
      "32  0.910256        (4120, 4026, 2742)\n",
      "33  0.910256        (4120, 4026, 2708)\n",
      "34  0.910256  (4120, 4026, 2708, 2742)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "import ast  # For safely evaluating string representations of lists\n",
    "\n",
    "\n",
    "def find_frequent_sequences_fp_growth(data, min_support=0.9):\n",
    "    \"\"\"\n",
    "    Finds the most frequent sequences of events for each incident type using FP-Growth.\n",
    "    \"\"\"\n",
    "    # Get all unique incident types\n",
    "    incident_types = data['incident_type'].unique()\n",
    "    results = {}\n",
    "\n",
    "    # Convert stringified lists to actual lists of integers\n",
    "    data['events_sequence'] = data['events_sequence'].apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    for incident in incident_types:\n",
    "        # Filter rows for the current incident type\n",
    "        filtered_data = data[data['incident_type'] == incident]\n",
    "\n",
    "        # Prepare transactions: each transaction is a sequence of events\n",
    "        transactions = filtered_data['events_sequence'].tolist()\n",
    "\n",
    "        # Create a one-hot encoded DataFrame for the events\n",
    "        unique_events = set(event for sequence in transactions for event in sequence)  # All unique events\n",
    "        transaction_df = pd.DataFrame([\n",
    "            {event: (event in sequence) for event in unique_events} for sequence in transactions\n",
    "        ])\n",
    "        print(transaction_df)\n",
    "        # Apply FP-Growth algorithm\n",
    "        # raise ValueError('stop')\n",
    "        frequent_itemsets = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "        # Sort by support and keep top results\n",
    "        if not frequent_itemsets.empty:\n",
    "            most_frequent = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "            results[incident] = most_frequent\n",
    "        else:\n",
    "            results[incident] = None\n",
    "        break\n",
    "        \n",
    "\n",
    "    return results\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('sncb_prepared.csv', sep=';')\n",
    "\n",
    "# Run the function\n",
    "results = find_frequent_sequences_fp_growth(data)\n",
    "\n",
    "# Display the results\n",
    "for incident, frequent in results.items():\n",
    "    print(f\"Incident Type: {incident}\")\n",
    "    if frequent is not None:\n",
    "        print(frequent)\n",
    "    else:\n",
    "        print(\"No frequent sequences found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4:      support                  itemsets\n",
      "0   1.000000                    (4026)\n",
      "8   1.000000              (4026, 2708)\n",
      "1   1.000000                    (2708)\n",
      "10  0.948718              (4026, 4148)\n",
      "9   0.948718              (2708, 4148)\n",
      "11  0.948718        (2708, 4026, 4148)\n",
      "2   0.948718                    (4148)\n",
      "5   0.935897                    (2742)\n",
      "4   0.935897                    (4066)\n",
      "3   0.935897                    (4068)\n",
      "22  0.935897              (2708, 2742)\n",
      "12  0.935897              (2708, 4068)\n",
      "13  0.935897              (4026, 4068)\n",
      "14  0.935897        (2708, 4026, 4068)\n",
      "15  0.935897              (4066, 2708)\n",
      "16  0.935897              (4026, 4066)\n",
      "18  0.935897        (4026, 2708, 4066)\n",
      "24  0.935897        (4026, 2708, 2742)\n",
      "23  0.935897              (4026, 2742)\n",
      "27  0.923077        (2708, 4026, 4394)\n",
      "26  0.923077              (4026, 4394)\n",
      "25  0.923077              (4394, 2708)\n",
      "17  0.923077              (4066, 4068)\n",
      "21  0.923077  (2708, 4026, 4068, 4066)\n",
      "20  0.923077        (4026, 4068, 4066)\n",
      "19  0.923077        (2708, 4066, 4068)\n",
      "6   0.923077                    (4394)\n",
      "7   0.910256                    (4120)\n",
      "28  0.910256              (4120, 2742)\n",
      "29  0.910256              (4120, 2708)\n",
      "30  0.910256              (4120, 4026)\n",
      "31  0.910256        (4120, 2708, 2742)\n",
      "32  0.910256        (4120, 4026, 2742)\n",
      "33  0.910256        (4120, 4026, 2708)\n",
      "34  0.910256  (4120, 4026, 2708, 2742)}\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "# filtered_freq = results[4]\n",
    "# filtered_freq = [(sup, item) for sup, item in zip(filtered_freq['support'], filtered_freq['itemsets']) if len(item) > 1]\n",
    "# print(filtered_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n",
      "919\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the rows of the DataFrame\n",
    "\n",
    "data = pd.read_csv('sncb_prepared.csv', sep=';')\n",
    "print(len(data['events_sequence']))\n",
    "counter = 0\n",
    "for index, row in data.iterrows():\n",
    "    # check if the numbers 2708, 4026, 4068, 4066 appear is in the events_sequence\n",
    "    if '2708' in row['events_sequence'] and '4026' in row['events_sequence'] and '4068' in row['events_sequence'] and '4066' in row['events_sequence']:\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
