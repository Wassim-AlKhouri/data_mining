{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a summary of the dj columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Create Summary column for the data ################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Synthetize the alimentation\n",
    "data = pd.read_csv('sncb_data_challenge.csv', sep=';')\n",
    "\n",
    "\n",
    "def str_to_bool_list(string):\n",
    "    # convert string to list of boolean\n",
    "    if pd.isna(string):\n",
    "        return []\n",
    "    return [s.strip() in 'True' for s in string.strip('[]').split(',')]\n",
    "\n",
    "# Convert string to list of boolean\n",
    "col_list_bool = ['dj_ac_state_sequence', 'dj_dc_state_sequence']\n",
    "\n",
    "for col in col_list_bool:\n",
    "    data[col] = data[col].apply(str_to_bool_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['events_sequence'] = data['events_sequence'].apply(lambda x: list(map(int, x.strip('[]').split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary column of the alimentation that will be had to the model\n",
    "data['summary'] = None\n",
    "for i in range(len(data[col_list_bool[0]])):\n",
    "    summary_list = []\n",
    "    for j in range(len(data[col_list_bool[0]][i])):\n",
    "        if data[col_list_bool[0]][i][j] and data[col_list_bool[1]][i][j]:\n",
    "            summary_list.append('AC/DC')\n",
    "        if data[col_list_bool[0]][i][j] and not data[col_list_bool[1]][i][j]:\n",
    "            summary_list.append('AC')\n",
    "        elif not data[col_list_bool[0]][i][j] and data[col_list_bool[1]][i][j]:\n",
    "            summary_list.append('DC')\n",
    "        else:\n",
    "            summary_list.append('Battery')\n",
    "    data.at[i, 'summary'] = summary_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work on the sequences of  the summary alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the sequence of the alimentation alone\n",
    "data['summary_alone'] = None\n",
    "for i in range(len(data['summary'])):\n",
    "    new_summary_list = []\n",
    "    for j in range(len(data['summary'][i])):\n",
    "        if j==0 or data['summary'][i][j] != data['summary'][i][j-1]:\n",
    "            new_summary_list.append(data['summary'][i][j])\n",
    "    data.at[i, 'summary_alone'] = new_summary_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Frequent itemsets (FP-Growth) #############################\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "import ast  # For safely evaluating string representations of lists\n",
    "\n",
    "\n",
    "def find_frequent_itemsets_fp_growth(data, min_support=0.3):\n",
    "    \"\"\"\n",
    "    Finds the most frequent sequences of events for each incident type using FP-Growth.\n",
    "    \"\"\"\n",
    "    # Get all unique incident types\n",
    "    incident_types = data['incident_type'].unique()\n",
    "    results = {}\n",
    "\n",
    "    for incident in incident_types:\n",
    "        # Check if the csv file already exists\n",
    "        try:\n",
    "            most_frequent = pd.read_csv(f'results\\\\results2\\\\results2_{incident}.csv', sep=';')\n",
    "            if most_frequent is not None:\n",
    "                results[incident] = most_frequent\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Filter rows for the current incident type\n",
    "        filtered_data = data[data['incident_type'] == incident]\n",
    "\n",
    "        # Prepare transactions: each transaction is a sequence of events\n",
    "        transactions = filtered_data['summary_alone']\n",
    "\n",
    "        # Create a one-hot encoded DataFrame for the events\n",
    "        unique_events = set(alimentation for sequence in transactions for alimentation in sequence)  # All unique events\n",
    "        transaction_df = pd.DataFrame([\n",
    "            {event: (event in sequence) for event in unique_events} for sequence in transactions\n",
    "        ])\n",
    "        # Apply FP-Growth algorithm\n",
    "        frequent_itemsets = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "        # Sort by support and keep top results\n",
    "        if not frequent_itemsets.empty:\n",
    "            most_frequent = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "            most_frequent['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: list(x))\n",
    "            results[incident] = most_frequent\n",
    "        else:\n",
    "            results[incident] = None\n",
    "        \n",
    "        # store the results in a csv file\n",
    "        most_frequent.to_csv(f'results\\\\results2\\\\results2_{incident}.csv', sep=';', index=False)\n",
    "    # Run for all the database\n",
    "    transactions = data['summary_alone']\n",
    "    unique_events = set(event for sequence in transactions for event in sequence)  # All unique events\n",
    "    transaction_df = pd.DataFrame([\n",
    "        {event: (event in sequence) for event in unique_events} for sequence in transactions\n",
    "    ])\n",
    "    database_frequent_itemsets = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
    "    database_frequent_itemsets = database_frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "    database_frequent_itemsets['itemsets'] = database_frequent_itemsets['itemsets'].apply(lambda x: list(x))\n",
    "    database_frequent_itemsets.to_csv(f'results\\\\results2\\\\results_database2.csv', sep=';', index=False)\n",
    "    return results\n",
    "\n",
    "# Run the function\n",
    "results = find_frequent_itemsets_fp_growth(data)\n",
    "\n",
    "# Display the results\n",
    "for incident, frequent in results.items():\n",
    "    print(f\"Incident Type: {incident}\")\n",
    "    if frequent is not None:\n",
    "        print(frequent)\n",
    "    else:\n",
    "        print(\"No frequent sequences found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work on a the combination between event and the summary colomn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most frequent sequence of alimentation combined with the event column\n",
    "\n",
    "data['events + summary'] = None\n",
    "for i in range(len(data['summary'])):\n",
    "    ev_sum_list = []\n",
    "    for j in range(len(data['summary'][i])):\n",
    "        ev_sum_list.append((data['events_sequence'][i][j], data['summary'][i][j]))\n",
    "    data.at[i, 'events + summary'] = ev_sum_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of duplicates in the 'events + summary' column\n",
    "\n",
    "for i in range(len(data['events + summary'])):\n",
    "    new_ev_sum_list = []\n",
    "    for j in range(len(data['events + summary'][i])):\n",
    "        if j == 0 or data['events + summary'][i][j] != data['events + summary'][i][j-1]:\n",
    "            new_ev_sum_list.append(data['events + summary'][i][j])\n",
    "    data.at[i, 'events + summary'] = new_ev_sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new alimentation\n",
    "data.to_csv('sncb_alimentation.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
